---
import { SiteTitle } from '../config';
import Card from './Card.astro';
---

<header>
  <Card>
    <div class="flex flex-row justify-between">
      <div class="flex max-[768px]:flex-col justify-center items-center">
        <span class="text-3xl">
          {SiteTitle}
        </span>
        <span id="time" class="text-3xl"></span>
        <div class="ms-4 text-3xl flex">
          {
            Array(12)
              .fill(null)
              .map((_, index) => (
                <div
                  id={`volumn_lv_${index + 1}`}
                  class="border-2 h-8 w-3 me-2 rounded"
                />
              ))
          }
        </div>
      </div>
      <div class="hover:cursor-pointer" id="btnMode" data-mode="light">
        <img
          id="icMode"
          src="/random-english-day/icons/dark_mode.svg"
          width="30px"
          height="30px"
        />
      </div>
    </div>
  </Card>
</header>

<script>
  function updateDateTime() {
    const now = new Date();

    const hours = String(now.getHours()).padStart(2, '0');
    const minutes = String(now.getMinutes()).padStart(2, '0');
    const seconds = String(now.getSeconds()).padStart(2, '0');
    const formattedDateTime = ` : ${hours}:${minutes}:${seconds}`;

    const timeElement = document.getElementById('time');
    timeElement.innerHTML = formattedDateTime;
  }

  const accessUserMicrophone = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });

      return stream;
    } catch (e) {
      console.error(e);
      alert('ไม่สามารถเข้าถึงไมโครโฟนของ user ได้');
      return;
    }
  };

  const processAudioStream = (stream: MediaStream) => {
    if (!stream.getAudioTracks().length) {
      console.error('No audio track available in the MediaStream');
      return;
    }

    const audioContext = new AudioContext(); //create AudioContext instance
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();

    analyser.fftSize = 1024; // assigned Fast Fourier Transform value
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    source.connect(analyser); //connect with analyser

    function update() {
      analyser.getByteFrequencyData(dataArray); // get sound data

      const volume = dataArray.reduce((a, b) => a + b, 0) / dataArray.length; // calculation sound volumn level average

      //color sound level
      const colors = [
        '#ffff00',
        '#ffee00',
        '#ffd900',
        '#ffc300',
        '#ffad00',
        '#ff9500',
        '#ff7d00',
        '#ff6500',
        '#ff4c00',
        '#ff3300',
        '#ff1a00',
        '#ff0000',
      ];

      colors.forEach((color, index) => {
        const bar = document.getElementById(`volumn_lv_${index + 1}`);
        if (bar) {
          if (volume > (index + 1) * 10) {
            bar.style.backgroundColor = color;
          } else {
            bar.style.backgroundColor = '';
          }
        }
      });

      // loop update sound volume level
      requestAnimationFrame(update);
    }

    update();
  };

  async function initMicrophone() {
    const stream = await accessUserMicrophone(); // request for permission to access microphone
    if (stream) {
      processAudioStream(stream); // send stream for process audio
    } else {
      console.error('Microphone not available');
    }
  }

  initMicrophone();
  setInterval(updateDateTime, 1000);
  updateDateTime();
</script>
